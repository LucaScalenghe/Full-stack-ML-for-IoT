{"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"tags":[],"cell_id":"ce9fdb353c01431c94570d6005068ec3","source_hash":"7a93dab8","execution_start":1671472427741,"execution_millis":1,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":1},"deepnote_to_be_reexecuted":false,"deepnote_app_is_code_hidden":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Set Deterministic Training","metadata":{"tags":[],"cell_id":"7108bf02ef3b47dbbf2b9564db433e47","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":13},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nfrom glob import glob\nfrom time import time\n\nseed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\nrandom.seed(seed)\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"tags":[],"cell_id":"8451494dacdf4abd9c02c529a1195d49","source_hash":"2274b898","execution_start":1671472429022,"execution_millis":0,"deepnote_app_coordinates":{"h":10,"w":12,"x":0,"y":18},"deepnote_to_be_reexecuted":false,"deepnote_app_is_code_hidden":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Define Hyper-Parameters","metadata":{"tags":[],"cell_id":"7819f7c080fb4ed180998d4a7833bfd2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"PREPROCESSING_ARGS = {\n    'downsampling_rate': 16000,\n    'frame_length_in_s': 0.016,\n    'frame_step_in_s': 0.016,\n    'lower_frequency': 20,\n    'upper_frequency': 4000,\n    'num_mel_bins': 40,\n    'num_coefficients': 10\n}\nTRAINING_ARGS = {\n    'batch_size': 20,\n    'initial_learning_rate': 0.01,\n    'end_learning_rate': 1.e-5,\n    'epochs': 30\n}\n\n#Optimization parameter\nalpha = 0.3\nfinal_sparsity = 0.80","metadata":{"tags":[],"cell_id":"ff9661c8866e4356b5050190a578e092","source_hash":"1eeaffb7","execution_start":1671472429753,"execution_millis":4,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":29},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Train/Val/Test datasets only with Stop/Go","metadata":{"tags":[],"cell_id":"ff4862c124bf4e219d9283ae4ee7f2f9","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":41},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"train_ds = tf.data.Dataset.list_files(['msc-train/go*', 'msc-train/stop*'])\nval_ds = tf.data.Dataset.list_files(['msc-val/go*', 'msc-val/stop*'])\ntest_ds = tf.data.Dataset.list_files(['msc-test/go*', 'msc-test/stop*'])","metadata":{"tags":[],"cell_id":"ea2fa7410990444fb8d072a92f711c09","source_hash":"42d7175f","execution_start":1671472431082,"execution_millis":4464,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Preprocess - Extraction of MFCC's","metadata":{"tags":[],"cell_id":"57f626bbec0341eb9a6086cf87037c95","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"from preprocessing import LABELS\nfrom preprocessing import get_mfccs\nfrom functools import partial\n\ndef get_mfccs_and_label(filename, downsampling_rate, frame_length_in_s, frame_step_in_s, num_mel_bins, lower_frequency, upper_frequency, num_coefficients):\n    mfccs, label = get_mfccs(filename, downsampling_rate,\n                            frame_length_in_s,\n                            frame_step_in_s,\n                            num_mel_bins,\n                            lower_frequency,\n                            upper_frequency,\n                            num_coefficients\n                            )\n    \n    return mfccs, label\n\n\n\n#Parameter freezing\nget_frozen_mfccs = partial(get_mfccs_and_label, **PREPROCESSING_ARGS)\n","metadata":{"tags":[],"cell_id":"b6503ddd09c941819f56010d2f23c089","source_hash":"299bf30","execution_start":1671472435550,"execution_millis":13,"deepnote_app_coordinates":{"h":24,"w":12,"x":0,"y":74},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def preprocess(filename):\n    #Get mfccs and then expand the dimension to then pass it to the model\n    processed_signal, label = get_frozen_mfccs(filename)\n    processed_signal = tf.expand_dims(processed_signal, -1) #because we need a 3d tensor for the model input\n\n    label_id = tf.argmax(label == LABELS)\n\n    return processed_signal, label_id    ","metadata":{"tags":[],"cell_id":"3b4da587d90e48438ab0399575987eef","source_hash":"484c83b0","execution_start":1671472435610,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Setting up batch size and number of epochs\nbatch_size = TRAINING_ARGS['batch_size']\nepochs = TRAINING_ARGS['epochs']\n\n#Preprocess all the datasets\ntrain_ds = train_ds.map(preprocess).batch(batch_size).cache()\nval_ds = val_ds.map(preprocess).batch(batch_size)\ntest_ds = test_ds.map(preprocess).batch(batch_size)","metadata":{"tags":[],"cell_id":"6f53595d24f945638d3f50fd5a62f901","source_hash":"b0b5ff36","execution_start":1671472435610,"execution_millis":1593,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-12-19 17:53:55.907307: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n2022-12-19 17:53:55.907529: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 AVX512F FMA\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n2022-12-19 17:53:56.213652: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:56.215118: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:56.215281: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n2022-12-19 17:53:56.559563: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:56.561110: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:56.561290: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n2022-12-19 17:53:57.010996: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:57.012566: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-12-19 17:53:57.012735: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Create the Model","metadata":{"tags":[],"cell_id":"fbdc3e067d7a4a059587ff71ff91acd8","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":123},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Infos on what the input of the model\nfor example_batch, example_labels in train_ds.take(1):\n  print('Batch Shape:', example_batch.shape)\n  print('Data Shape:', example_batch.shape[1:])\n  print('Labels:', example_labels)","metadata":{"tags":[],"cell_id":"53b4d2615c254dd9840582201a298229","source_hash":"4d19bea2","execution_start":1671472438912,"execution_millis":454,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Batch Shape: (20, 62, 10, 1)\nData Shape: (62, 10, 1)\nLabels: tf.Tensor([0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0], shape=(20,), dtype=int64)\n2022-12-19 17:53:59.297761: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"for example_batch, example_labels in train_ds.take(1):\n    pass\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    \n    # ----------------------- Normal convolution  ------------------------------------------\n    tf.keras.layers.Conv2D(filters=int(256 * alpha), kernel_size=[3, 3], strides=[2, 2],\n        use_bias=False, padding='valid'),\n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.ReLU(),\n    # ----------------------- Depth wise convolution 2 ------------------------------------------\n    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], \n        use_bias=False, padding='same'),\n    \n    tf.keras.layers.Conv2D(filters=int(256 * alpha), kernel_size=[1, 1], strides=[1, 1],   \n       use_bias=False),\n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.ReLU(),\n\n    # ----------------------- Depth wise convolution 3 ------------------------------------------    \n    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n        use_bias=False, padding='same'),\n    \n    tf.keras.layers.Conv2D(filters=int(256 * alpha), kernel_size=[1, 1], strides=[1, 1],   \n       use_bias=False),\n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.ReLU(),\n    \n    tf.keras.layers.GlobalAveragePooling2D(),\n    \n    tf.keras.layers.Dense(units=len(LABELS)),\n    \n    tf.keras.layers.Softmax()\n])\nprint('filters are of dimension:', int(256 * alpha))","metadata":{"tags":[],"cell_id":"10b86f3fba894aaead240429990a8696","source_hash":"f6c346f","execution_start":1671472439845,"execution_millis":453,"deepnote_app_coordinates":{"h":13,"w":12,"x":0,"y":109},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"filters are of dimension: 76\n2022-12-19 17:54:00.088052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.summary()","metadata":{"tags":[],"cell_id":"0b7492d614164c5198115d9502b4cf58","source_hash":"4e6a3b95","execution_start":1671472442429,"execution_millis":27,"deepnote_app_coordinates":{"h":27,"w":12,"x":0,"y":141},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 30, 4, 76)         684       \n                                                                 \n batch_normalization (BatchN  (None, 30, 4, 76)        304       \n ormalization)                                                   \n                                                                 \n re_lu (ReLU)                (None, 30, 4, 76)         0         \n                                                                 \n depthwise_conv2d (Depthwise  (None, 30, 4, 76)        684       \n Conv2D)                                                         \n                                                                 \n conv2d_1 (Conv2D)           (None, 30, 4, 76)         5776      \n                                                                 \n batch_normalization_1 (Batc  (None, 30, 4, 76)        304       \n hNormalization)                                                 \n                                                                 \n re_lu_1 (ReLU)              (None, 30, 4, 76)         0         \n                                                                 \n depthwise_conv2d_1 (Depthwi  (None, 30, 4, 76)        684       \n seConv2D)                                                       \n                                                                 \n conv2d_2 (Conv2D)           (None, 30, 4, 76)         5776      \n                                                                 \n batch_normalization_2 (Batc  (None, 30, 4, 76)        304       \n hNormalization)                                                 \n                                                                 \n re_lu_2 (ReLU)              (None, 30, 4, 76)         0         \n                                                                 \n global_average_pooling2d (G  (None, 76)               0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 2)                 154       \n                                                                 \n softmax (Softmax)           (None, 2)                 0         \n                                                                 \n=================================================================\nTotal params: 14,670\nTrainable params: 14,214\nNon-trainable params: 456\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Setup Magnitude-based Weights Pruning","metadata":{"tags":[],"cell_id":"8ace23e1bc73486993deaa2f2837b6be","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"import tensorflow_model_optimization as tfmot\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\nbegin_step = int(len(train_ds) * epochs * 0.2)\nend_step = int(len(train_ds) * epochs)\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.20,\n        final_sparsity=final_sparsity,\n        begin_step=begin_step,\n        end_step=end_step\n    )\n}\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)\nmodel_for_pruning.summary()","metadata":{"tags":[],"cell_id":"e3ac9f230c58452aa6dbde9d7f01820d","source_hash":"4b91564d","execution_start":1671472444629,"execution_millis":765,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d   (None, 30, 4, 76)        1370      \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization (PruneLowMagni                                     \n tude)                                                           \n                                                                 \n prune_low_magnitude_re_lu (  (None, 30, 4, 76)        1         \n PruneLowMagnitude)                                              \n                                                                 \n prune_low_magnitude_depthwi  (None, 30, 4, 76)        685       \n se_conv2d (PruneLowMagnitud                                     \n e)                                                              \n                                                                 \n prune_low_magnitude_conv2d_  (None, 30, 4, 76)        11554     \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization_1 (PruneLowMag                                     \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu_1  (None, 30, 4, 76)        1         \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_depthwi  (None, 30, 4, 76)        685       \n se_conv2d_1 (PruneLowMagnit                                     \n ude)                                                            \n                                                                 \n prune_low_magnitude_conv2d_  (None, 30, 4, 76)        11554     \n 2 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization_2 (PruneLowMag                                     \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu_2  (None, 30, 4, 76)        1         \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_global_  (None, 76)               1         \n average_pooling2d (PruneLow                                     \n Magnitude)                                                      \n                                                                 \n prune_low_magnitude_dense (  (None, 2)                308       \n PruneLowMagnitude)                                              \n                                                                 \n prune_low_magnitude_softmax  (None, 2)                1         \n  (PruneLowMagnitude)                                            \n                                                                 \n=================================================================\nTotal params: 27,076\nTrainable params: 14,214\nNon-trainable params: 12,862\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Train the Model","metadata":{"tags":[],"cell_id":"caed2f8e50e14e65a584a031d8bc2de0","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":169},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\ninitial_learning_rate = TRAINING_ARGS['initial_learning_rate']\nend_learning_rate = TRAINING_ARGS['end_learning_rate']\n\nlinear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=initial_learning_rate,\n    end_learning_rate=end_learning_rate,\n    decay_steps=len(train_ds) * epochs,\n)\noptimizer = tf.optimizers.Adam(learning_rate=linear_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\ncallbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n\n#Compiling and running the model\nmodel_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\nhistory = model_for_pruning.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)","metadata":{"tags":[],"cell_id":"160dc5ed7d59462a85c660c046bca94f","source_hash":"c95fc2d1","execution_start":1671472445675,"execution_millis":117593,"deepnote_app_coordinates":{"h":29,"w":12,"x":0,"y":174},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 1/30\n80/80 [==============================] - 11s 105ms/step - loss: 0.4641 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.4251 - val_sparse_categorical_accuracy: 0.8100\nEpoch 2/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.3405 - sparse_categorical_accuracy: 0.8600 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.7500\nEpoch 3/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.2941 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.4610 - val_sparse_categorical_accuracy: 0.8350\nEpoch 4/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.2466 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8200\nEpoch 5/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.2155 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.8550\nEpoch 6/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.1942 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.8950\nEpoch 7/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9394 - val_loss: 0.3845 - val_sparse_categorical_accuracy: 0.8600\nEpoch 8/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.2326 - val_sparse_categorical_accuracy: 0.9150\nEpoch 9/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.1239 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.4969 - val_sparse_categorical_accuracy: 0.8450\nEpoch 10/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.3422 - val_sparse_categorical_accuracy: 0.8700\nEpoch 11/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.8050\nEpoch 12/30\n80/80 [==============================] - 3s 44ms/step - loss: 0.0866 - sparse_categorical_accuracy: 0.9675 - val_loss: 0.3175 - val_sparse_categorical_accuracy: 0.8950\nEpoch 13/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1892 - val_sparse_categorical_accuracy: 0.9250\nEpoch 14/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1778 - val_sparse_categorical_accuracy: 0.9200\nEpoch 15/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.8800\nEpoch 16/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9200\nEpoch 17/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1545 - val_sparse_categorical_accuracy: 0.9300\nEpoch 18/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8600\nEpoch 19/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.1922 - val_sparse_categorical_accuracy: 0.9200\nEpoch 20/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.3839 - val_sparse_categorical_accuracy: 0.8800\nEpoch 21/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9806 - val_loss: 5.2751 - val_sparse_categorical_accuracy: 0.5750\nEpoch 22/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.2467 - val_sparse_categorical_accuracy: 0.9050\nEpoch 23/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9737 - val_loss: 0.1819 - val_sparse_categorical_accuracy: 0.9300\nEpoch 24/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1674 - val_sparse_categorical_accuracy: 0.9250\nEpoch 25/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.1603 - val_sparse_categorical_accuracy: 0.9350\nEpoch 26/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9300\nEpoch 27/30\n80/80 [==============================] - 4s 47ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.1473 - val_sparse_categorical_accuracy: 0.9350\nEpoch 28/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0447 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.1438 - val_sparse_categorical_accuracy: 0.9400\nEpoch 29/30\n80/80 [==============================] - 4s 46ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9400\nEpoch 30/30\n80/80 [==============================] - 4s 45ms/step - loss: 0.0404 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.1488 - val_sparse_categorical_accuracy: 0.9400\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# How each layer got pruned\n\nfor layer in model_for_pruning.layers:\n    if isinstance(layer, tf.keras.layers.Wrapper):\n        weights = layer.trainable_weights\n    else:\n        weights = layer.weights\n    for weight in weights:        \n        weight_size = weight.numpy().size\n        zero_num = np.count_nonzero(weight == 0)\n        print(\n            f'{weight.name}: {zero_num/weight_size:.2%} sparsity ',\n            f'({zero_num}/{weight_size})',\n        )","metadata":{"tags":[],"cell_id":"c6bd745b4cbf408b8dbb446be5c7c3b7","source_hash":"b4364524","execution_start":1671472563270,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"conv2d/kernel:0: 79.97% sparsity  (547/684)\nbatch_normalization/gamma:0: 0.00% sparsity  (0/76)\nbatch_normalization/beta:0: 0.00% sparsity  (0/76)\ndepthwise_conv2d/depthwise_kernel:0: 0.00% sparsity  (0/684)\nconv2d_1/kernel:0: 80.00% sparsity  (4621/5776)\nbatch_normalization_1/gamma:0: 0.00% sparsity  (0/76)\nbatch_normalization_1/beta:0: 0.00% sparsity  (0/76)\ndepthwise_conv2d_1/depthwise_kernel:0: 0.00% sparsity  (0/684)\nconv2d_2/kernel:0: 80.00% sparsity  (4621/5776)\nbatch_normalization_2/gamma:0: 0.00% sparsity  (0/76)\nbatch_normalization_2/beta:0: 0.00% sparsity  (0/76)\ndense/kernel:0: 80.26% sparsity  (122/152)\ndense/bias:0: 0.00% sparsity  (0/2)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Test the model","metadata":{"tags":[],"cell_id":"b4e6a475f1ce417eb4c4d4f79b1f5bd0","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":233},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)","metadata":{"tags":[],"cell_id":"899de2a36baf429893e8b73ff01ba1f9","source_hash":"ddc77961","execution_start":1671472563280,"execution_millis":994,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":238},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"10/10 [==============================] - 1s 56ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9750\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"training_loss = history.history['loss'][-1]\ntraining_accuracy = history.history['sparse_categorical_accuracy'][-1]\nval_loss = history.history['val_loss'][-1]\nval_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n\nprint(f'Weight pruning with final_sparsity= {final_sparsity}')\nprint(f'Training Loss: {training_loss:.4f}')\nprint(f'Training Accuracy: {training_accuracy*100.:.2f}%')\nprint()\nprint(f'Validation Loss: {val_loss:.4f}')\nprint(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\nprint()\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy*100.:.2f}%')\n\nprint(model_for_pruning.summary())","metadata":{"tags":[],"cell_id":"84def3bf3e8e45b1a254b7df3405dc5c","source_hash":"1d365df1","execution_start":1671472564277,"execution_millis":110,"deepnote_app_coordinates":{"h":18,"w":12,"x":0,"y":244},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Weight pruning with final_sparsity= 0.8\nTraining Loss: 0.0404\nTraining Accuracy: 98.94%\n\nValidation Loss: 0.1488\nValidation Accuracy: 94.00%\n\nTest Loss: 0.0732\nTest Accuracy: 97.50%\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d   (None, 30, 4, 76)        1370      \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization (PruneLowMagni                                     \n tude)                                                           \n                                                                 \n prune_low_magnitude_re_lu (  (None, 30, 4, 76)        1         \n PruneLowMagnitude)                                              \n                                                                 \n prune_low_magnitude_depthwi  (None, 30, 4, 76)        685       \n se_conv2d (PruneLowMagnitud                                     \n e)                                                              \n                                                                 \n prune_low_magnitude_conv2d_  (None, 30, 4, 76)        11554     \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization_1 (PruneLowMag                                     \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu_1  (None, 30, 4, 76)        1         \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_depthwi  (None, 30, 4, 76)        685       \n se_conv2d_1 (PruneLowMagnit                                     \n ude)                                                            \n                                                                 \n prune_low_magnitude_conv2d_  (None, 30, 4, 76)        11554     \n 2 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_batch_n  (None, 30, 4, 76)        305       \n ormalization_2 (PruneLowMag                                     \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu_2  (None, 30, 4, 76)        1         \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_global_  (None, 76)               1         \n average_pooling2d (PruneLow                                     \n Magnitude)                                                      \n                                                                 \n prune_low_magnitude_dense (  (None, 2)                308       \n PruneLowMagnitude)                                              \n                                                                 \n prune_low_magnitude_softmax  (None, 2)                1         \n  (PruneLowMagnitude)                                            \n                                                                 \n=================================================================\nTotal params: 27,076\nTrainable params: 14,214\nNon-trainable params: 12,862\n_________________________________________________________________\nNone\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Save the Model","metadata":{"tags":[],"cell_id":"9994d94eda2c47758f61dec7e8b6c686","deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":263},"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Save Keras Model","metadata":{"tags":[],"cell_id":"dd7254fd48254ce1974ea2c9bab0d164","deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":268},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from time import time\n\ntimestamp = int(time())\nMODEL_NAME = 'model11'\nsaved_model_dir = f'./saved_models/{MODEL_NAME}'\nif not os.path.exists(saved_model_dir):\n    os.makedirs(saved_model_dir)\nmodel.save(saved_model_dir)","metadata":{"tags":[],"cell_id":"f3bd3727d3144910849c7158796fff63","source_hash":"1a3a23f","execution_start":1671472564433,"execution_millis":1161,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":272},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nWARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\nINFO:tensorflow:Assets written to: ./saved_models/model11/assets\nINFO:tensorflow:Assets written to: ./saved_models/model11/assets\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### Save Hyper-Parameters and Results","metadata":{"tags":[],"cell_id":"d5c7f95b4246439d8ca7471e45d94d95","deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":284},"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import pandas as pd\n\noutput_dict = {\n    'timestamp': timestamp,\n    **PREPROCESSING_ARGS,\n    **TRAINING_ARGS,\n    'test_accuracy': test_accuracy\n}\n\ndf = pd.DataFrame([output_dict])\n\noutput_path='./spectrogram_results.csv'\ndf.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)","metadata":{"tags":[],"cell_id":"28f425b83ce340d798d65ff9d174a43b","source_hash":"dddbd8d9","execution_start":1671472565597,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Convert the model if needed (could be skipped but also simply run it all)","metadata":{"tags":[],"cell_id":"426d67235ba348bb8544b614586bf7b6","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"!ls saved_models","metadata":{"tags":[],"cell_id":"eee5da87866a4edaab5468a5ad7eda70","source_hash":"db0e61c2","execution_start":1671472565608,"execution_millis":231,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"1670594974  model11\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"MODEL_NAME = 'model11'","metadata":{"tags":[],"cell_id":"be569431766e4782ae4db83265420fb7","source_hash":"c8f45e96","execution_start":1671472565841,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":27},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models/{MODEL_NAME}')\ntflite_model = converter.convert()\n\ntflite_models_dir = './tflite_models'\nif not os.path.exists(tflite_models_dir):\n    os.makedirs(tflite_models_dir)\n\ntflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\nwith open(tflite_model_name, 'wb') as fp:\n    fp.write(tflite_model)\n\n!ls tflite_models","metadata":{"tags":[],"cell_id":"3f8c3afd57a644d083ea621e6a0614be","source_hash":"9ac8cbf7","execution_start":1671472565889,"execution_millis":676,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"model11.tflite\tmodel11.tflite.zip\n2022-12-19 17:56:06.173312: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n2022-12-19 17:56:06.173352: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n2022-12-19 17:56:06.174003: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./saved_models/model11\n2022-12-19 17:56:06.176608: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n2022-12-19 17:56:06.176633: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: ./saved_models/model11\n2022-12-19 17:56:06.182005: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n2022-12-19 17:56:06.183396: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n2022-12-19 17:56:06.215012: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: ./saved_models/model11\n2022-12-19 17:56:06.224467: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 50471 microseconds.\n2022-12-19 17:56:06.244634: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Zipping the TFLite model","metadata":{"tags":[],"cell_id":"9198f517d70446978f73d507aea7a266","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"import zipfile\n\ntflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\n\nwith zipfile.ZipFile(f'{tflite_model_name}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n    f.write(tflite_model_name)","metadata":{"tags":[],"cell_id":"733d397df798496c8883daffd5d53976","source_hash":"20f93133","execution_start":1671472566569,"execution_millis":6,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":29},{"cell_type":"code","source":"!ls tflite_models","metadata":{"tags":[],"cell_id":"c25062f5f1654a74b44f063ad20d802c","source_hash":"c060602f","execution_start":1671472566580,"execution_millis":265,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"model11.tflite\tmodel11.tflite.zip\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"tflite_size = os.path.getsize(tflite_model_name) / 1024.0\nzipped_size = os.path.getsize(f'{tflite_model_name}.zip') / 1024.0\n\nprint(f'Original tflite size: {tflite_size:.3f} KB')\nprint(f'Zipped tflite size : {zipped_size:.3f} KB')","metadata":{"tags":[],"cell_id":"89cb17c58eee4fbb80a2f1b98e1d5880","source_hash":"c1d79293","execution_start":1671472566848,"execution_millis":22,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Original tflite size: 58.691 KB\nZipped tflite size : 22.340 KB\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3b2bd993-aace-454c-8357-5037007c606e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_app_layout":"article","deepnote_notebook_id":"9747ddf4ffce487c8a2cd3c64b2652dd","deepnote_execution_queue":[]}}